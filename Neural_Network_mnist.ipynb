{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7: Code a simple neural network\n",
    "\n",
    "In this exercise you will code up a simple neurtal network from scratch and test it on the well-known MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import all important libraries for the network class\n",
    "import numpy as np\n",
    "# And scipy for the sigmoid function expit()\n",
    "import scipy as sp\n",
    "# Import matplotlib so we can look at the data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a neural network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network class\n",
    "class neuralNetwork:\n",
    "        \n",
    "    # Initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # Set the number of nodes for each layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # Link weight matrices\n",
    "        # You can either use np.random.rand between -0.5 and 0.5 or np.random.normal with 1/sqrt(Nnodesperlayer)\n",
    "        self.wih = np.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # Activation function\n",
    "        # Use the sigmod function for this exercise: sp.special.expit\n",
    "        self.af = lambda x: sp.special.expit(x)\n",
    "        \n",
    "        # Nothing to return\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # Now we need a function to train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # First convert the inputs list to 2d array\n",
    "        inputs  = np.array(inputs_list,  ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # Propagate signal forward from input to hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # And get the signal processed by the activation function\n",
    "        hidden_outputs = self.af(hidden_inputs)\n",
    "        \n",
    "        # Propagate signal forward from hidden to output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # And get the signal processed by the activation function\n",
    "        final_outputs = self.af(final_inputs)\n",
    "        \n",
    "        # Output layer error is the (target - outputs)\n",
    "        output_errors = targets - final_outputs\n",
    "        # Backpropagate the error to the hidden layer\n",
    "        # Hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = np.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # Update the hidden-output weights\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        \n",
    "        # Update the input-hidden weights\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "        # Nothing to return\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # And finally a function to query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # Convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # And same as above\n",
    "        # Propagate signal forward from input to hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # And get the signal processed by the activation function\n",
    "        hidden_outputs = self.af(hidden_inputs)\n",
    "        \n",
    "        # Propagate signal forward from hidden to output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # And get the signal processed by the activation function\n",
    "        final_outputs = self.af(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MNIST dataset from scikit learn\n",
    "# Make sure you upgrade sklearn to version 0.20 (or higher)\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "# Define the features and the labels\n",
    "X, y = mnist['data'], np.asfarray(mnist['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,) float64 float64\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape,X.dtype,y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some index, get the corresponding image, and plot it\n",
    "some_index = 4\n",
    "some_digit = X[some_index]\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "plt.imshow(some_digit_image, cmap=cm.jet, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "# Check the label\n",
    "y[some_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and test set\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "# Shuffle the training set to make sure training goes smooth\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can train the neural network\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    # Print the current epoch\n",
    "    print('Epoch', e)\n",
    "    # Go through all instances in the training data set\n",
    "    for i in range(y_train.size):\n",
    "        # Scale and shift the inputs with a minimum of 0.01 and maximum of 1.0\n",
    "        inputs = (X_train[i] / 255.0 * 0.99) + 0.01\n",
    "        # Create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        # The target label for this instance is y_train[i]\n",
    "        targets[int(y_train[i])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the predictions for some examples\n",
    "# Define some index, get the corresponding image and label\n",
    "some_index = 111\n",
    "some_digit_image = X_test[some_index].copy().reshape(28,28)\n",
    "some_digit   = (X_test[some_index]/ 255.0 * 0.99) + 0.01\n",
    "target_label = np.int64(y_test[some_index])\n",
    "\n",
    "# Query the network for the predicted label\n",
    "network_output  = n.query(some_digit)\n",
    "predicted_label = np.argmax(network_output)\n",
    "print('True label:',target_label,' - Predicted label:',predicted_label)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap=cm.jet, interpolation='nearest')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for i in range(y_test.size):\n",
    "    # correct answer is first value\n",
    "    correct_label = np.int64(y_test[i])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (X_test[i] / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print (\"Performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now we try it with Keras (TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to import TensorFlow\n",
    "# You can install it via 'pip install --upgrade tensorflow'\n",
    "import tensorflow as tf\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 159,010\n",
      "Trainable params: 159,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define a simple MLP with Keras (Lego-Style)\n",
    "model = tf.keras.models.Sequential()\n",
    "# Add an input layer - a Dense layer is basically a Perceptron\n",
    "#model.add(tf.keras.layers.Dense(input_nodes, input_shape=(input_nodes,)))\n",
    "# Add first hidden layer \n",
    "model.add(tf.keras.layers.Dense(hidden_nodes, activation='sigmoid', input_shape=(input_nodes,)))\n",
    "# Add an output layer \n",
    "model.add(tf.keras.layers.Dense(output_nodes, activation='sigmoid'))\n",
    "# Get some information about the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd  = tf.keras.optimizers.SGD(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform label into array of categories using one-hot encoding\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, output_nodes)\n",
    "y_test_cat  = tf.keras.utils.to_categorical(y_test,  output_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0196 - acc: 0.9044\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0159 - acc: 0.9179\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0140 - acc: 0.9265\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0133 - acc: 0.9304\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0125 - acc: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a613cfc50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat, epochs=5, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0118 - acc: 0.9375\n",
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_cat,verbose=1)\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the network prediction for the test sample\n",
    "network_output  = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape,network_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 5  - Predicted label: 5\n"
     ]
    }
   ],
   "source": [
    "# Let's check the predictions for some examples\n",
    "# Define some index, get the corresponding label\n",
    "some_index = 540\n",
    "target_label = np.int64(y_test[some_index])\n",
    "# Query the network for the predicted label\n",
    "predicted_label = np.argmax(network_output[some_index])\n",
    "print('True label:',target_label,' - Predicted label:',predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more things to do\n",
    "\n",
    "Test if you can get a better performance. Some things to vary:\n",
    "\n",
    "* Change the network architecture, i.e. number of hidden layers and noden in the hidden layers\n",
    "* Change the activation function. See: https://keras.io/activations/\n",
    "* Change the optimizer. See: https://keras.io/optimizers/\n",
    "* Change the loss function (e.g. try categorical_crossentropy). See: https://keras.io/losses/\n",
    "* Change the number of epochs and the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
